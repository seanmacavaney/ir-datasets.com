name: Downloadable Content, HEAD

on:
  schedule:
    - cron: '0 8 * * 1-6' # run every day except sunday at (around) 8:00am UTC
  workflow_dispatch:
    inputs:
      dataset:
        description: "Top-level dataset ID to run (or leave blank for all)" 
        required: false
        default: ''

jobs:

  create_branch:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - run: git checkout -b head-downloads-${{github.run_number}} --track
    - run: 'echo ${{github.run_number}}-head > docs/dlc/_placeholder.txt'
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/_placeholder.txt'
        message: 'touch'
        author_name: GitHub Actions
        author_email: actions@github.com





  antique:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'antique'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^antique/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/antique.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: antique' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  aol-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aol-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^aol-ia/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aol-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: aol-ia' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  aquaint:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aquaint'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^aquaint/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aquaint.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: aquaint' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  argsme:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'argsme'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^argsme/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/argsme.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: argsme' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  beir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'beir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^beir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/beir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: beir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  c4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'c4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^c4/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/c4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: c4' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  car:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'car'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^car/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/car.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: car' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  clinicaltrials:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clinicaltrials'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clinicaltrials/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clinicaltrials.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: clinicaltrials' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  clirmatrix:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clirmatrix'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clirmatrix/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clirmatrix.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: clirmatrix' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  clueweb09:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb09'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clueweb09/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb09.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: clueweb09' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  clueweb12:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb12'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^clueweb12/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb12.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: clueweb12' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  codec:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codec'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^codec/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codec.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: codec' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  codesearchnet:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codesearchnet'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^codesearchnet/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codesearchnet.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: codesearchnet' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  cord19:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cord19'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^cord19/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cord19.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: cord19' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  cranfield:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cranfield'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^cranfield/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cranfield.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: cranfield' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  disks45:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'disks45'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^disks45/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/disks45.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: disks45' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  dpr-w100:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'dpr-w100'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^dpr-w100/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/dpr-w100.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: dpr-w100' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  gov:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^gov/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: gov' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  gov2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^gov2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: gov2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  hc4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'hc4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^hc4/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/hc4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: hc4' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  highwire:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'highwire'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^highwire/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/highwire.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: highwire' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  istella22:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'istella22'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^istella22/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/istella22.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: istella22' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  kilt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'kilt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^kilt/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/kilt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: kilt' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  lotte:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'lotte'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^lotte/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/lotte.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: lotte' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  medline:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'medline'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^medline/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/medline.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: medline' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  miracl:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'miracl'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^miracl/" --output download.new.json --randdelay 5
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/miracl.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: miracl' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  mmarco:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mmarco'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^mmarco/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mmarco.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: mmarco' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  mr-tydi:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mr-tydi'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^mr-tydi/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mr-tydi.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: mr-tydi' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  msmarco-document:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-document/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: msmarco-document' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  msmarco-document-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-document-v2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: msmarco-document-v2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  msmarco-passage:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-passage/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: msmarco-passage' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  msmarco-passage-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-passage-v2/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: msmarco-passage-v2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  msmarco-qna:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-qna'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^msmarco-qna/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-qna.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: msmarco-qna' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  natural-questions:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'natural-questions'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^natural-questions/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/natural-questions.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: natural-questions' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  neuclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'neuclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^neuclir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/neuclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: neuclir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  neumarco:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'neumarco'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^neumarco/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/neumarco.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: neumarco' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  nfcorpus:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nfcorpus'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^nfcorpus/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nfcorpus.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: nfcorpus' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  nyt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nyt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^nyt/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nyt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: nyt' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  pmc:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'pmc'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^pmc/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/pmc.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: pmc' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  sara:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'sara'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^sara/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/sara.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: sara' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  touche:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'touche'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^touche/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/touche.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: touche' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  touche-image:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'touche-image'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^touche-image/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/touche-image.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: touche-image' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-arabic:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-arabic'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-arabic/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-arabic.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-arabic' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-cast:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-cast'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-cast/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-cast.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-cast' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-fair:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-fair'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-fair/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-fair.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-fair' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-fair-2021:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-fair-2021'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-fair-2021/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-fair-2021.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-fair-2021' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-mandarin:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-mandarin'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-mandarin/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-mandarin.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-mandarin' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-robust04:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-robust04'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-robust04/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-robust04.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-robust04' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-spanish:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-spanish'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-spanish/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-spanish.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-spanish' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  trec-tot:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-tot'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^trec-tot/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-tot.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: trec-tot' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  tripclick:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tripclick'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^tripclick/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tripclick.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: tripclick' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  tweets2013-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tweets2013-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^tweets2013-ia/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tweets2013-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: tweets2013-ia' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  vaswani:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'vaswani'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^vaswani/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/vaswani.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: vaswani' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  wapo:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wapo'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wapo/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wapo.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: wapo' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  wikiclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikiclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wikiclir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikiclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: wikiclir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  wikir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: head-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --head_precheck --filter "^wikir/" --output download.new.json --randdelay 10
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'head_downloads: wikir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi

  merge_dlc:
    if: ${{ always() }}
    needs: [antique, aol-ia, aquaint, argsme, beir, c4, car, clinicaltrials, clirmatrix, clueweb09, clueweb12, codec, codesearchnet, cord19, cranfield, disks45, dpr-w100, gov, gov2, hc4, highwire, istella22, kilt, lotte, medline, miracl, mmarco, mr-tydi, msmarco-document, msmarco-document-v2, msmarco-passage, msmarco-passage-v2, msmarco-qna, natural-questions, neuclir, neumarco, nfcorpus, nyt, pmc, sara, touche, touche-image, trec-arabic, trec-cast, trec-fair, trec-fair-2021, trec-mandarin, trec-robust04, trec-spanish, trec-tot, tripclick, tweets2013-ia, vaswani, wapo, wikiclir, wikir]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        ref: head-downloads-${{github.run_number}}
        fetch-depth: 0
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - run: |
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        python merge_dlc.py
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/*.json'
        message: 'from head_downloads'
        author_name: GitHub Actions
        author_email: actions@github.com
    - run: |
        git checkout master
        git merge -s recursive -Xtheirs --squash head-downloads-${{github.run_number}} --allow-unrelated-histories
        git commit -m head-downloads-${{github.run_number}}
        git push origin master
        git push origin --delete head-downloads-${{github.run_number}}
