name: Downloadable Content

on:
  schedule:
    - cron: '0 8 * * 0' # run every sunday at (around) 8:00am UTC
  workflow_dispatch:
    inputs:
      dataset:
        description: "Top-level dataset ID to run (or leave blank for all)" 
        required: false
        default: ''

jobs:

  create_branch:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - run: git checkout -b verify-downloads-${{github.run_number}} --track
    - run: 'echo ${{github.run_number}}-verify > docs/dlc/_placeholder.txt'
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/_placeholder.txt'
        message: 'touch'
        author_name: GitHub Actions
        author_email: actions@github.com





  antique:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'antique'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^antique/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/antique.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: antique' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  aol-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aol-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^aol-ia/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aol-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: aol-ia' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  aquaint:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'aquaint'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^aquaint/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/aquaint.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: aquaint' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  argsme:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'argsme'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^argsme/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/argsme.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: argsme' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  beir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'beir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^beir/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/beir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: beir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  c4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'c4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^c4/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/c4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: c4' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  car:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'car'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^car/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/car.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: car' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  clinicaltrials:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clinicaltrials'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^clinicaltrials/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clinicaltrials.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: clinicaltrials' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  clirmatrix:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clirmatrix'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^clirmatrix/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clirmatrix.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: clirmatrix' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  clueweb09:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb09'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^clueweb09/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb09.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: clueweb09' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  clueweb12:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'clueweb12'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^clueweb12/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/clueweb12.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: clueweb12' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  codec:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codec'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^codec/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codec.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: codec' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  codesearchnet:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'codesearchnet'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^codesearchnet/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/codesearchnet.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: codesearchnet' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  cord19:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cord19'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^cord19/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cord19.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: cord19' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  cranfield:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'cranfield'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^cranfield/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/cranfield.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: cranfield' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  disks45:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'disks45'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^disks45/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/disks45.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: disks45' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  dpr-w100:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'dpr-w100'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^dpr-w100/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/dpr-w100.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: dpr-w100' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  gov:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^gov/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: gov' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  gov2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'gov2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^gov2/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/gov2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: gov2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  hc4:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'hc4'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^hc4/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/hc4.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: hc4' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  highwire:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'highwire'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^highwire/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/highwire.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: highwire' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  kilt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'kilt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^kilt/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/kilt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: kilt' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  lotte:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'lotte'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^lotte/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/lotte.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: lotte' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  medline:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'medline'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^medline/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/medline.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: medline' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  mmarco:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mmarco'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^mmarco/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mmarco.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: mmarco' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  mr-tydi:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'mr-tydi'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^mr-tydi/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/mr-tydi.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: mr-tydi' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  msmarco-document:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^msmarco-document/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: msmarco-document' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  msmarco-document-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-document-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^msmarco-document-v2/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-document-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: msmarco-document-v2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  msmarco-passage:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^msmarco-passage/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: msmarco-passage' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  msmarco-passage-v2:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-passage-v2'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^msmarco-passage-v2/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-passage-v2.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: msmarco-passage-v2' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  msmarco-qna:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'msmarco-qna'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^msmarco-qna/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/msmarco-qna.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: msmarco-qna' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  natural-questions:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'natural-questions'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^natural-questions/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/natural-questions.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: natural-questions' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  neuclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'neuclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^neuclir/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/neuclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: neuclir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  neumarco:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'neumarco'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^neumarco/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/neumarco.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: neumarco' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  nfcorpus:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nfcorpus'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^nfcorpus/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nfcorpus.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: nfcorpus' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  nyt:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'nyt'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^nyt/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/nyt.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: nyt' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  pmc:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'pmc'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^pmc/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/pmc.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: pmc' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  touche:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'touche'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^touche/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/touche.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: touche' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-arabic:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-arabic'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-arabic/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-arabic.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-arabic' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-cast:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-cast'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-cast/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-cast.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-cast' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-fair:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-fair'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-fair/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-fair.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-fair' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-fair-2021:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-fair-2021'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-fair-2021/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-fair-2021.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-fair-2021' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-mandarin:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-mandarin'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-mandarin/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-mandarin.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-mandarin' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-robust04:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-robust04'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-robust04/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-robust04.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-robust04' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  trec-spanish:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'trec-spanish'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^trec-spanish/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/trec-spanish.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: trec-spanish' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  tripclick:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tripclick'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^tripclick/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tripclick.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: tripclick' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  tweets2013-ia:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'tweets2013-ia'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^tweets2013-ia/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/tweets2013-ia.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: tweets2013-ia' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  vaswani:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'vaswani'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^vaswani/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/vaswani.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: vaswani' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  wapo:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wapo'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^wapo/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wapo.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: wapo' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  wikiclir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikiclir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^wikiclir/" --output download.new.json --randdelay 60
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikiclir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: wikiclir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  wikir:
    if: "!github.event.inputs.dataset || github.event.inputs.dataset == 'wikir'"
    needs: [create_branch]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        repository: allenai/ir_datasets
        path: ir-datasets
    - uses: actions/checkout@v2
      with:
        path: ir-datasets.com
        ref: verify-downloads-${{github.run_number}}
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        cd ir-datasets
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Test
      env:
        IR_DATASETS_DL_DISABLE_PBAR: 'true'
      run: |
        cd ir-datasets
        python -m test.downloads --filter "^wikir/" --output download.new.json
    - name: Upload
      if: always()
      run: |
        cd ir-datasets
        python ../ir-datasets.com/merge_history.py download.new.json "../ir-datasets.com/docs/dlc/wikir.json"
        cd ../ir-datasets.com/
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        git pull --rebase --autostash
        git add docs/dlc/*.json
        if git commit -m 'verify_downloads: wikir' ; then
            until git push
            do
              echo trying again
              git pull --rebase --autostash
            done
            echo success
        fi
  merge_dlc:
    if: ${{ always() }}
    needs: [antique, aol-ia, aquaint, argsme, beir, c4, car, clinicaltrials, clirmatrix, clueweb09, clueweb12, codec, codesearchnet, cord19, cranfield, disks45, dpr-w100, gov, gov2, hc4, highwire, kilt, lotte, medline, mmarco, mr-tydi, msmarco-document, msmarco-document-v2, msmarco-passage, msmarco-passage-v2, msmarco-qna, natural-questions, neuclir, neumarco, nfcorpus, nyt, pmc, touche, trec-arabic, trec-cast, trec-fair, trec-fair-2021, trec-mandarin, trec-robust04, trec-spanish, tripclick, tweets2013-ia, vaswani, wapo, wikiclir, wikir]
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        ref: verify-downloads-${{github.run_number}}
        fetch-depth: 0
    - uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    - run: |
        git config user.email "actions@github.com"
        git config user.name "GitHub Actions"
        python merge_dlc.py
    - uses: EndBug/add-and-commit@v8
      with:
        add: 'docs/dlc/*.json'
        message: 'from verify_downloads'
        author_name: GitHub Actions
        author_email: actions@github.com
    - run: |
        git checkout master
        git merge -s recursive -Xtheirs --squash verify-downloads-${{github.run_number}} --allow-unrelated-histories
        git commit -m verify-downloads-${{github.run_number}}
        git push origin master
        git push origin --delete verify-downloads-${{github.run_number}}
